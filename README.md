# TPE ISSD - Reconnaissance d'Expressions Faciales avec un Robot Furhat

<div align="center">

![Python](https://img.shields.io/badge/python-v3.10-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-v2.6+-red.svg)

**SystÃ¨me de reconnaissance d'expressions faciales en temps rÃ©el intÃ©grÃ© avec le robot humanoÃ¯de <a href="https://furhatrobotics.com/">Furhat</a>**

</div>

## ğŸ“‹ Table des MatiÃ¨res

- [ğŸ¯ Description du Projet](#-description-du-projet)
- [ğŸ“‹ Architecture](#-architecture)
- [ğŸš€ Installation](#-installation)
- [ğŸ® Utilisation](#-utilisation)
- [ğŸ“Š Structure du Projet](#-structure-du-projet)
- [ğŸ§  ModÃ¨les SupportÃ©s](#-modÃ¨les-supportÃ©s)
- [ğŸ¤– Ã€ propos de Furhat](#-Ã -propos-de-furhat)
- [ğŸ“ˆ Performances](#-performances)

## ğŸ¯ Description du Projet

Ce projet vise Ã  implÃ©menter un **systÃ¨me de reconnaissance des expressions faciales en temps rÃ©el** en utilisant des mÃ©thodes de deep learning. Il capture les visages Ã  l'aide d'une camÃ©ra puis les analyse avec un modÃ¨le de classification d'images.

Le modÃ¨le est entraÃ®nÃ© sur le jeu de donnÃ©es ImageNet (plusieurs modÃ¨les disponibles), fine-tunÃ© une premiÃ¨re fois sur le jeu de donnÃ©es d'expressions faciales FER2013 afin de classifier des expressions faciales, puis fine-tunÃ© une nouvelle fois sur un jeu de donnÃ©es privÃ©, Ã©laborÃ© spÃ©cialement pour le projet.
On fait ensuite rÃ©agir le robot humanoÃ¯de [Furhat](https://furhatrobotics.com/) en rÃ©action Ã  l'expression dÃ©tectÃ©e, en utilisant notamment des expressions faciales disponibles sur le robot, des LED et de la synthÃ¨se vocale.

### ğŸ­ Expressions Reconnues

Le systÃ¨me peut dÃ©tecter, Ã  partir du dataset FER2013, **7 expressions faciales diffÃ©rentes**. On choisit ici de se limiter Ã  **4 expressions** afin d'avoir de meilleurs rÃ©sultats (on exclut la surprise, la peur et l'expression "neutre" qui sont plus difficiles Ã  classifier):

- ğŸ˜  **ColÃ¨re** (Angry) - LED rouge, expression de colÃ¨re
- ğŸ˜¨ **Peur** (Fear) - LED violette, expression de peur
- ğŸ˜Š **Joie** (Happy) - LED jaune, grand sourire
- ğŸ˜¢ **Tristesse** (Sad) - LED bleue, expression triste

## ğŸ“‹ Architecture

**Pipeline de traitement :**

1. **Capture** : Capture des images en temps rÃ©el via une camÃ©ra connectÃ©e au PC via USB
2. **DÃ©tection** : Localisation des visages et redimensionnement avec OpenCV
3. **Traitement** : Augmentation des donnÃ©es (rotation, zoom, etc.) pour amÃ©liorer la robustesse de la prÃ©diction
4. **InfÃ©rence** : Classification avec modÃ¨le prÃ©-entraÃ®nÃ© par batch d'images (permet une prÃ©diction plus robuste par moyennage des prÃ©dictions obtenues sur une certaine pÃ©riode de temps)
5. **RÃ©action** : Synchronisation au robot Furhat et rÃ©action en fonction de l'expression dÃ©tectÃ©e (expression, voix, LEDs)

## ğŸš€ Installation

### PrÃ©requis

- ğŸ¥ **CamÃ©ra quelconque** / **CamÃ©ra RealSense** (_si vous souhaitez utiliser le projet directement_)
- ğŸ¤– **Robot Furhat** avec connexion rÃ©seau (voir [documentation](https://docs.furhat.io) et configuration pour obtenir son adresse IP) et furhat-remote-api activÃ©e sur le robot

### 1. Installer uv (Gestionnaire de dÃ©pendances)

Pour gÃ©rer les dÃ©pendances, ce projet utilise [uv](https://docs.astral.sh/uv), un gestionnaire de paquets Python bien plus rapide que pip qui gÃ¨re automatiquement les environnements virtuels.

#### ğŸ§ Linux / ğŸ macOS

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

#### ğŸªŸ Windows

```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. Cloner le Projet

```bash
git clone https://github.com/fab-toc/FER_Furhat.git
cd FER_Furhat
```

### 3. Installer les DÃ©pendances

Le choix des dÃ©pendances PyTorch dÃ©pend de votre configuration matÃ©rielle :

#### ğŸ”¥ Avec GPU NVIDIA

Identifiez d'abord votre version CUDA :

```bash
nvidia-smi
```

Puis installez selon votre version :

```bash
# CUDA 11.8
uv sync --extra cu118

# CUDA 12.4
uv sync --extra cu124

# CUDA 12.6
uv sync --extra cu126

# CUDA 12.8
uv sync --extra cu128
```

#### ğŸ’» Autres Configurations

```bash
# CPU uniquement
uv sync --extra cpu
```

### 4. Configuration Kaggle (Optionnel)

Pour tÃ©lÃ©charger automatiquement le dataset FER2013 (dans le cas oÃ¹ vous souhaitez fine-tuner le modÃ¨le et l'entraÃ®ner), vous pouvez configurer vos identifiants Kaggle :

```bash
# Copier le template
cp .env.example .env

# Ã‰diter avec vos credentials Kaggle
nano .env
```

Ajoutez vos identifiants Kaggle :

```bash
export KAGGLE_USERNAME=votre_username
export KAGGLE_KEY=votre_api_key
```

## ğŸ® Utilisation

### ğŸš€ DÃ©marrage Rapide

1. **Connecter la camÃ©ra RealSense**
2. **S'assurer que Furhat est accessible sur le rÃ©seau et bien configurÃ©**
3. **Lancer l'application principale** :

```bash
uv run src/main.py
```

### ğŸ“Š EntraÃ®nement d'un Nouveau ModÃ¨le

```bash
# EntraÃ®nement initial
uv run src/train/train.py

# Fine-tuning sur vos donnÃ©es
uv run src/train/fine-tuning.py
```

### ğŸ§ª Test et Ã‰valuation de ModÃ¨les

```bash
# Test sur dataset
uv run src/test.py
```

## ğŸ“Š Structure du Projet

```
FER_Furhat/
â”œâ”€â”€ ğŸ“ src/                    # Code source principal
â”‚   â”œâ”€â”€ ğŸ main.py             # Application principale (pipeline complet de reconnaissance d'expressions faciales et rÃ©actions avec le robot)
â”‚   â”œâ”€â”€ ğŸ§ª test.py             # Test et Ã©valuation de modÃ¨les
â”‚   â””â”€â”€ ğŸ“ train/              # Scripts d'entraÃ®nement
â”‚       â”œâ”€â”€ ğŸ”§ utils.py        # Fonctions utilitaires, d'entraÃ®nement, de deep learning, etc.
â”‚       â”œâ”€â”€ ğŸ¯ train.py        # EntraÃ®nement d'un modÃ¨le (fine-tuning sur le dataset FER2013)
â”‚       â””â”€â”€ âš¡ fine-tuning.py   # Fine-tuning sur un dataset privÃ©
â”œâ”€â”€ ğŸ“ trained/                # RÃ©pertoire des modÃ¨les entraÃ®nÃ©s sauvegardÃ©s (auto-gÃ©nÃ©rÃ© lors de la sauvegarde d'un modÃ¨le aprÃ¨s entraÃ®nement)
â”‚   â””â”€â”€ ğŸ“ (model_name)        # RÃ©pertoire spÃ©cifique Ã  une famille de modÃ¨les sauvegardÃ©s (auto-gÃ©nÃ©rÃ© lors de la sauvegarde d'un modÃ¨le aprÃ¨s entraÃ®nement)
â”œâ”€â”€ ğŸ“ dataset/                # RÃ©pertoire d'un potentiel dataset privÃ© (Ã  crÃ©er)
â”œâ”€â”€ âš™ï¸ pyproject.toml          # Configuration du projet, des dÃ©pendances, des scripts, etc.
â”œâ”€â”€ ğŸ”’ .env.example            # Template variables d'environnement
â””â”€â”€ ğŸ“– README.md               # Cette documentation
```

## ğŸ§  ModÃ¨les SupportÃ©s

### ğŸ—ï¸ Architectures

| ModÃ¨le       | Variantes                  | ParamÃ¨tres  | Performance |
| ------------ | -------------------------- | ----------- | ----------- |
| **ConvNeXt** | Tiny, Small, Base, Large   | 28M - 197M  | â­â­â­â­â­  |
| **VGG**      | VGG11, VGG13, VGG16, VGG19 | 132M - 143M | â­â­â­â­    |

### âš™ï¸ Configuration RecommandÃ©e

```python
MODEL_NAME = "convnext"
MODEL_VERSION = "large"        # Meilleure prÃ©cision
UNFREEZE_LAYER = 3            # Fine-tuning optimal
BATCH_SIZE = 32               # Ã‰quilibre vitesse/mÃ©moire
```

## ğŸ¤– Ã€ propos de Furhat

[Furhat Robotics](https://furhatrobotics.com/) dÃ©veloppe des robots sociaux avec des capacitÃ©s d'interaction naturelle. Notre systÃ¨me utilise :

### ğŸ­ CapacitÃ©s Furhat UtilisÃ©es

- **Expressions faciales** : 20+ expressions programmables
- **SynthÃ¨se vocale** : Voix multilingues (franÃ§ais supportÃ©)
- **LEDs** : Ã‰clairage RGB personnalisable
- **API REST** : ContrÃ´le via HTTP/WebSocket

### ğŸ”§ Configuration RÃ©seau

Par dÃ©faut, le systÃ¨me cherche le robot Furhat sur `192.168.10.14:54321`. Modifiez dans `main.py` :

```python
furhat_controller = FurhatController(host="VOTRE_IP_FURHAT")
```

## ğŸ“ˆ Performances

### ğŸ¯ MÃ©triques Typiques

| Dataset                     | ModÃ¨le         | PrÃ©cision |
| --------------------------- | -------------- | --------- |
| FER2013                     | ConvNeXt-Large | ~60%      |
| Fine-tunÃ© sur notre dataset | ConvNeXt-Large | ~90%      |
