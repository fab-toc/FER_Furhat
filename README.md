# TPE ISSD - Reconnaissance d'Expressions Faciales avec Robot Furhat

<div align="center">

![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-v2.6+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

**Un systÃ¨me de reconnaissance d'expressions faciales en temps rÃ©el intÃ©grÃ© avec le robot humanoÃ¯de Furhat**

[ğŸš€ Installation](#installation) â€¢ [ğŸ“– Documentation](#documentation) â€¢ [ğŸ¯ Utilisation](#utilisation) â€¢ [ğŸ¤– Ã€ propos de Furhat](#Ã -propos-de-furhat)

</div>

---

## ğŸ“‹ Table des MatiÃ¨res

- [ğŸ¯ Description du Projet](#-description-du-projet)
- [âœ¨ FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸš€ Installation](#-installation)
- [ğŸ® Utilisation](#-utilisation)
- [ğŸ“Š Structure du Projet](#-structure-du-projet)
- [ğŸ§  ModÃ¨les SupportÃ©s](#-modÃ¨les-supportÃ©s)
- [ğŸ¤– Ã€ propos de Furhat](#-Ã -propos-de-furhat)
- [ğŸ”§ Configuration AvancÃ©e](#-configuration-avancÃ©e)
- [ğŸ“ˆ Performances](#-performances)
- [ğŸ¤ Contribution](#-contribution)

---

## ğŸ¯ Description du Projet

Ce projet implÃ©mente un **systÃ¨me de reconnaissance d'expressions faciales en temps rÃ©el** utilisant des techniques de deep learning. Le systÃ¨me capture les expressions via une camÃ©ra Intel RealSense, les analyse avec un modÃ¨le ConvNeXt ou VGG prÃ©-entraÃ®nÃ©, puis fait rÃ©agir le robot humanoÃ¯de **[Furhat](https://www.furhatrobotics.com/)** en consÃ©quence.

### ğŸ­ Expressions Reconnues

Le systÃ¨me peut dÃ©tecter et rÃ©agir Ã  **4 expressions principales** :

- ğŸ˜  **ColÃ¨re** (Angry) - LED rouge, expression de colÃ¨re
- ğŸ˜¨ **Peur** (Fear) - LED violette, expression de peur
- ğŸ˜Š **Joie** (Happy) - LED jaune, grand sourire
- ğŸ˜¢ **Tristesse** (Sad) - LED bleue, expression triste

---

## âœ¨ FonctionnalitÃ©s

- ğŸ¥ **Capture en temps rÃ©el** avec camÃ©ra Intel RealSense
- ğŸ§  **Deep Learning** avec modÃ¨les ConvNeXt/VGG prÃ©-entraÃ®nÃ©s
- ğŸ¤– **IntÃ©gration Furhat** complÃ¨te (voix, expressions, LEDs)
- ğŸ¯ **DÃ©tection de visages** avec OpenCV
- âš¡ **Traitement asynchrone** pour performances optimales
- ğŸ¨ **Interface visuelle** avec affichage en temps rÃ©el
- ğŸ”§ **Configuration flexible** des hyperparamÃ¨tres
- ğŸ“Š **Fine-tuning** sur donnÃ©es personnalisÃ©es

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[CamÃ©ra RealSense] --> B[DÃ©tection Visages]
    B --> C[Preprocessing]
    C --> D[ModÃ¨le ConvNeXt/VGG]
    D --> E[Classification Ã‰motions]
    E --> F[ContrÃ´leur Furhat]
    F --> G[Expression + Voix + LED]
```

**Pipeline de traitement :**

1. **Capture** : Images en temps rÃ©el via RealSense
2. **DÃ©tection** : Localisation des visages avec Haar Cascades
3. **Traitement** : Redimensionnement et augmentation des donnÃ©es
4. **InfÃ©rence** : Classification avec modÃ¨le prÃ©-entraÃ®nÃ©
5. **RÃ©action** : Synchronisation Furhat (expression, voix, LEDs)

---

## ğŸš€ Installation

### PrÃ©requis

- ğŸ **Python 3.10+**
- ğŸ¥ **CamÃ©ra Intel RealSense** (D415, D435, etc.)
- ğŸ¤– **Robot Furhat** avec connexion rÃ©seau
- ğŸ’» **SystÃ¨me compatible** : Linux, Windows, macOS

### 1. Installer uv (Gestionnaire de dÃ©pendances)

uv est un gestionnaire de paquets Python ultra-rapide qui gÃ¨re automatiquement les environnements virtuels.

#### ğŸ§ Linux / ğŸ macOS

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

#### ğŸªŸ Windows

```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. Cloner le Projet

```bash
git clone https://github.com/votre-username/TPE_FER_Furhat.git
cd TPE_FER_Furhat
```

### 3. Installer les DÃ©pendances

Le choix des dÃ©pendances PyTorch dÃ©pend de votre configuration matÃ©rielle :

#### ğŸ”¥ Avec GPU NVIDIA

Identifiez d'abord votre version CUDA :

```bash
nvidia-smi
```

Puis installez selon votre version :

```bash
# CUDA 11.8
uv sync --extra cu118

# CUDA 12.4
uv sync --extra cu124

# CUDA 12.6
uv sync --extra cu126

# CUDA 12.8
uv sync --extra cu128
```

#### ğŸ’» Autres Configurations

```bash
# CPU uniquement
uv sync --extra cpu

# GPU AMD (Linux uniquement)
uv sync --extra rocm

# GPU Intel (Linux/Windows)
uv sync --extra xpu
```

### 4. Configuration Kaggle (Optionnel)

Pour tÃ©lÃ©charger automatiquement le dataset FER2013 :

```bash
# Copier le template
cp .env.example .env

# Ã‰diter avec vos credentials Kaggle
nano .env
```

Ajoutez vos identifiants Kaggle :

```bash
export KAGGLE_USERNAME=votre_username
export KAGGLE_KEY=votre_api_key
```

---

## ğŸ® Utilisation

### ğŸš€ DÃ©marrage Rapide

1. **Connecter la camÃ©ra RealSense**
2. **S'assurer que Furhat est accessible** sur le rÃ©seau
3. **Lancer l'application principale** :

```bash
uv run src/main.py
```

### ğŸ“Š EntraÃ®nement d'un Nouveau ModÃ¨le

```bash
# EntraÃ®nement initial
uv run src/train/train.py

# Fine-tuning sur vos donnÃ©es
uv run src/train/fine-tuning.py
```

### ğŸ§ª Test de ModÃ¨les

```bash
# Test sur dataset
uv run src/test.py

# Test de connexion Furhat
uv run src/test_furhat.py
```

---

## ğŸ“Š Structure du Projet

```
TPE_FER_Furhat/
â”œâ”€â”€ ğŸ“ src/                     # Code source principal
â”‚   â”œâ”€â”€ ğŸ main.py             # Application principale
â”‚   â”œâ”€â”€ ğŸ§ª test.py             # Tests de modÃ¨les
â”‚   â”œâ”€â”€ ğŸ¤– test_furhat.py      # Test connexion Furhat
â”‚   â””â”€â”€ ğŸ“ train/              # Scripts d'entraÃ®nement
â”‚       â”œâ”€â”€ ğŸ”§ utils.py        # Utilitaires ML
â”‚       â”œâ”€â”€ ğŸ¯ train.py        # EntraÃ®nement initial
â”‚       â””â”€â”€ âš¡ fine-tuning.py  # Fine-tuning
â”œâ”€â”€ ğŸ“ trained/                # ModÃ¨les sauvegardÃ©s (auto-gÃ©nÃ©rÃ©)
â”œâ”€â”€ ğŸ“ dataset/                # Dataset local (auto-tÃ©lÃ©chargÃ©)
â”œâ”€â”€ âš™ï¸ pyproject.toml          # Configuration projet
â”œâ”€â”€ ğŸ”’ .env.example            # Template variables environnement
â””â”€â”€ ğŸ“– README.md               # Ce fichier
```

### ğŸ§© Composants Principaux

#### `src/main.py` - Application Principale

- **FurhatController** : Gestion robot (voix, expressions, LEDs)
- **InMemoryFaceDataset** : Dataset optimisÃ© pour l'infÃ©rence
- **Pipeline temps rÃ©el** : Capture â†’ Traitement â†’ InfÃ©rence â†’ RÃ©action

#### `src/train/utils.py` - Utilitaires ML

- [`get_model()`](src/train/utils.py) : Factory de modÃ¨les (VGG/ConvNeXt)
- [`get_data_transforms()`](src/train/utils.py) : Pipeline de preprocessing
- [`train_classifier_with_validation()`](src/train/utils.py) : Boucle d'entraÃ®nement
- [`eval_classifier()`](src/train/utils.py) : Ã‰valuation de performance

---

## ğŸ§  ModÃ¨les SupportÃ©s

### ğŸ—ï¸ Architectures

| ModÃ¨le       | Variantes                  | ParamÃ¨tres  | Performance |
| ------------ | -------------------------- | ----------- | ----------- |
| **ConvNeXt** | Tiny, Small, Base, Large   | 28M - 197M  | â­â­â­â­â­  |
| **VGG**      | VGG11, VGG13, VGG16, VGG19 | 132M - 143M | â­â­â­â­    |

### âš™ï¸ Configuration RecommandÃ©e

```python
MODEL_NAME = "convnext"
MODEL_VERSION = "large"        # Meilleure prÃ©cision
UNFREEZE_LAYER = 3            # Fine-tuning optimal
BATCH_SIZE = 32               # Ã‰quilibre vitesse/mÃ©moire
```

---

## ğŸ¤– Ã€ propos de Furhat

[Furhat Robotics](https://www.furhatrobotics.com/) dÃ©veloppe des robots sociaux avec des capacitÃ©s d'interaction naturelle. Notre systÃ¨me utilise :

### ğŸ­ CapacitÃ©s Furhat UtilisÃ©es

- **Expressions faciales** : 20+ expressions programmables
- **SynthÃ¨se vocale** : Voix multilingues (franÃ§ais supportÃ©)
- **LEDs** : Ã‰clairage RGB personnalisable
- **API REST** : ContrÃ´le via HTTP/WebSocket

### ğŸ”§ Configuration RÃ©seau

Par dÃ©faut, le systÃ¨me cherche Furhat sur `192.168.10.14:54321`. Modifiez dans `main.py` :

```python
furhat_controller = FurhatController(host="VOTRE_IP_FURHAT")
```

---

## ğŸ”§ Configuration AvancÃ©e

### ğŸ¯ HyperparamÃ¨tres d'EntraÃ®nement

```python
# Dans train.py ou fine-tuning.py
EMOTIONS_TO_EXCLUDE = ["surprise", "neutral", "disgust"]
AUGMENTATION_LEVEL = "heavy"    # none, light, medium, heavy
BATCH_SIZE = 256               # Ajuster selon GPU
EPOCHS = 15                    # Nombre d'Ã©poques
LR = 1e-4                      # Taux d'apprentissage
```

### ğŸ¥ ParamÃ¨tres CamÃ©ra

```python
# Dans main.py
NUM_IMAGES = 60               # Images par batch d'infÃ©rence
cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 60)
```

### ğŸ¤– Personnalisation Furhat

```python
# Messages par Ã©motion (dans FurhatController)
self.messages = {
    "happy": ["Je suis heureux!", "Quelle joie!"],
    "sad": ["Je me sens triste...", "La mÃ©lancolie me gagne."]
}

# Couleurs LED personnalisÃ©es
self.colors = {
    "happy": {"r": 255, "g": 255, "b": 0},  # Jaune
    "angry": {"r": 255, "g": 0, "b": 0}     # Rouge
}
```

---

## ğŸ“ˆ Performances

### ğŸ¯ MÃ©triques Typiques

| Dataset                     | ModÃ¨le         | PrÃ©cision |
| --------------------------- | -------------- | --------- |
| FER2013                     | ConvNeXt-Large | ~60%      |
| Fine-tunÃ© sur notre dataset | ConvNeXt-Large | ~90%      |
